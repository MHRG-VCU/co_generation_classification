{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simultaneous generation-classification using LSTM \n",
    "Implementation of the paper: Simultaneous Generation-classification using lstm \n",
    "\n",
    "Authors: Daniel L. Marino, Kasun Amarasinghe, Milos Manic\n",
    "\n",
    "This script implements the training using Generation and Classification as objective"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#************************************************************************\n",
    "#      __   __  _    _  _____   _____\n",
    "#     /  | /  || |  | ||     \\ /  ___|\n",
    "#    /   |/   || |__| ||    _||  |  _\n",
    "#   / /|   /| ||  __  || |\\ \\ |  |_| |\n",
    "#  /_/ |_ / |_||_|  |_||_| \\_\\|______|\n",
    "#    \n",
    "#\n",
    "#   Copyright (2016) Modern Heuristics Research Group (MHRG)\n",
    "#   Virginia Commonwealth University (VCU), Richmond, VA\n",
    "#   http://www.people.vcu.edu/~mmanic/\n",
    "#   \n",
    "#   This program is free software: you can redistribute it and/or modify\n",
    "#   it under the terms of the GNU General Public License as published by\n",
    "#   the Free Software Foundation, either version 3 of the License, or\n",
    "#   (at your option) any later version.\n",
    "#\n",
    "#   This program is distributed in the hope that it will be useful,\n",
    "#   but WITHOUT ANY WARRANTY; without even the implied warranty of\n",
    "#   MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n",
    "#   GNU General Public License for more details.\n",
    "#  \n",
    "#   Any opinions, findings, and conclusions or recommendations expressed \n",
    "#   in this material are those of the author's(s') and do not necessarily \n",
    "#   reflect the views of any other entity.\n",
    "#  \n",
    "#   ***********************************************************************\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import random\n",
    "import tensorflow as tf\n",
    "import pickle\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "from six.moves import range\n",
    "import time\n",
    "\n",
    "from twodlearn.tf_lib.Feedforward import LinearLayer\n",
    "from twodlearn.tf_lib.Recurrent import *\n",
    "\n",
    "import sys\n",
    "working_dir= os.getcwd()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Configuration Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "allow_gpu= True\n",
    "allow_valid= True\n",
    "allow_test= True\n",
    "Valid_Percentage= 0.1 # i.e. 10% of the data will be used for validation\n",
    "\n",
    "pos_net_name= '_pos'\n",
    "neg_net_name= '_neg'\n",
    "\n",
    "activation_function='tanh'\n",
    "num_nodes = [100, 100] #num_nodes: Nodes for the LSTM cell\n",
    "alpha = 10.0 #0.1 #0.1\n",
    "beta = 0.1 #0.01 #10000.01\n",
    "lambda_w = 0.00001\n",
    "\n",
    "dropout_cons = 0.8\n",
    "\n",
    "Allow_Bias= False \n",
    "\n",
    "learning_rate= 0.005      # 0.001\n",
    "grad_clip_thresh= 1.1       # 0.00001\n",
    "\n",
    "current_run= 1\n",
    "batch_size= 64 #64\n",
    "num_unrollings= 64 #100\n",
    "\n",
    "batch_size_val= 64 #len(valid_text_pos)/num_unrollings_val #500\n",
    "num_unrollings_val= num_unrollings #100\n",
    "\n",
    "batch_size_test= 64 \n",
    "num_unrollings_test= num_unrollings #100\n",
    "\n",
    "comment='_noDropout_LcLpLcp_64unrol_standarloss'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_nodes: [100, 100]\n",
      "alpha: 10.0 , beta: 0.1 , lambda_w: 1e-05\n",
      "num_unrollings: 64 , batch_size: 64 , batch_size_val: 64\n",
      "learning_rate: 0.005 grad_clip_thresh: 1.1\n"
     ]
    }
   ],
   "source": [
    "model_version = 'L'+str(len(num_nodes))\n",
    "print(\"num_nodes:\",num_nodes)\n",
    "print(\"alpha:\",alpha, \", beta:\",beta,\", lambda_w:\", lambda_w)\n",
    "print(\"num_unrollings:\",num_unrollings, \", batch_size:\",batch_size,\", batch_size_val:\", batch_size_val)\n",
    "print(\"learning_rate:\", learning_rate, 'grad_clip_thresh:', grad_clip_thresh)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Load training dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### First, you need to run imdb_download_and_preprocessing.ipynb to download and preprocess the imdb dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "65\n",
      "(64, 1)\n",
      "(64, 4001)\n",
      "profession would have over taken a car and blown away the terrorist insid i think that sum up what s wrong with thi seri thi is the worst movi i ve ever seen i m not kid the next time it come on i will just continu run my head into a wall it would me more enjoy to sit in an emerg room tri \n",
      "[ 0.]\n",
      "the stori as the nice twist end make the stori come aliv the second while not bad at all is probabl the weakest peter play a who is for a girl friend who die some time ago though the pictur of her look amazingli contemporari when he enter a of horror museum in town he see a figur that remind him of hi lost ladi \n",
      "[ 1.]\n"
     ]
    }
   ],
   "source": [
    "vc= pickle.load( open( \"imdb_vc.pkl\", \"rb\" ) )\n",
    "num_inputs=  vc.vocabulary_size\n",
    "num_outputs= vc.vocabulary_size\n",
    "\n",
    "dataset= pickle.load( open( \"imdb_dataset.pkl\", \"rb\" ) )\n",
    "\n",
    "# set batch_size and number of unrolligns\n",
    "dataset.train.set_batch_and_unrollings(batch_size, num_unrollings)\n",
    "dataset.valid.set_batch_and_unrollings(batch_size_val, num_unrollings_val)\n",
    "dataset.test.set_batch_and_unrollings(batch_size_test, num_unrollings_test)\n",
    "\n",
    "# print a sample of the dataset\n",
    "train_x, train_y= dataset.train.next_batch()\n",
    "print(len(train_x))\n",
    "print(train_y.shape)\n",
    "print(train_x[0].shape)\n",
    "\n",
    "print(vc.keys2text([np.argmax(train_x[i][0,:], 0) for i in range(len(train_x))]))\n",
    "print(train_y[0])\n",
    "\n",
    "print(vc.keys2text([np.argmax(train_x[i][50,:], 0) for i in range(len(train_x))]))\n",
    "print(train_y[50])\n",
    "\n",
    "valid_x, valid_y= dataset.valid.next_batch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# inputs: 4001\n",
      "pos train length: 2467794\n",
      "neg train length: 2467794\n",
      "pos valid length: 274199\n",
      "neg valid length: 274199\n",
      "pos test length: 2685859\n",
      "neg test length: 2685859\n"
     ]
    }
   ],
   "source": [
    "print('# inputs:',num_inputs)\n",
    "\n",
    "print('pos train length:',dataset.train.batch_generators[0]._text_size )\n",
    "print('neg train length:',dataset.train.batch_generators[1]._text_size )\n",
    "\n",
    "print('pos valid length:',dataset.valid.batch_generators[0]._text_size )\n",
    "print('neg valid length:',dataset.valid.batch_generators[1]._text_size )\n",
    "\n",
    "print('pos test length:',dataset.test.batch_generators[0]._text_size )\n",
    "print('neg test length:',dataset.test.batch_generators[1]._text_size )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Auxiliary functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def classification_error(predictions, labels):\n",
    "    \"\"\" number of samples wrongly classified  \"\"\"\n",
    "    return np.sum( np.not_equal( np.greater(predictions, 0.5), \n",
    "                                 np.greater(labels, 0.5)) )/labels.shape[0]\n",
    "\n",
    "def logprob(predictions, labels):\n",
    "    \"\"\"Log-probability of the true labels in a predicted batch.\"\"\"\n",
    "    predictions[predictions < 1e-10] = 1e-10 # this is to prevent that log() returns minus infinity\n",
    "    return np.sum(np.multiply(labels, -np.log(predictions))) / labels.shape[0]\n",
    "\n",
    "def sample_distribution(distribution):\n",
    "    \"\"\"Sample one element from a distribution assumed to be an array of normalized\n",
    "    probabilities.\n",
    "    \"\"\"\n",
    "    r = random.uniform(0, 1)\n",
    "    s = 0\n",
    "    for i in range(len(distribution)):\n",
    "        s += distribution[i]\n",
    "        if s >= r:\n",
    "            return i\n",
    "    return len(distribution) - 1\n",
    "\n",
    "def sample(prediction):\n",
    "    \"\"\"Turn a (column) prediction into 1-hot encoded samples.\"\"\"\n",
    "    p = np.zeros(shape=[1, vc.vocabulary_size], dtype=np.float)\n",
    "    p[0, sample_distribution(prediction[0])] = 1.0\n",
    "    return p\n",
    "\n",
    "def random_distribution():\n",
    "    \"\"\"Generate a random column of probabilities.\"\"\"\n",
    "    b = np.random.uniform(0.0, 1.0, size=[1, vc.vocabulary_size])\n",
    "    return b/np.sum(b, 1)[:,None]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Model for positive and negative reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class myLstmNet(LstmNet):\n",
    "    def get_extra_inputs(self, i, h_list, state_list):\n",
    "        #print('OK:', len(h_list))\n",
    "        return i\n",
    "    \n",
    "    def evaluate_final_output(self, outputs_list, inputs_list, h_list ):\n",
    "        ''' Calculates the final output of the neural network, usually it is just a linear transformation\n",
    "            - outputs_list: list with the outputs from the last lstm cell\n",
    "            - inputs_list: list of inputs to the network\n",
    "            - h_list: list with all hidden outputs from all the cells\n",
    "        '''\n",
    "        all_hidden = list()\n",
    "        \n",
    "        for t in h_list: # go trough each time step\n",
    "            all_hidden.append( tf.concat(1,t) )\n",
    "        return self.out_layer.evaluate(tf.concat(0, all_hidden))  \n",
    "            \n",
    "    \n",
    "if len(num_nodes)>1:\n",
    "    n_extra= [num_inputs for i in range(len(num_nodes)+1)]\n",
    "    n_extra[0]= 0\n",
    "    n_extra[-1]= sum(num_nodes) - num_nodes[-1]\n",
    "else:\n",
    "    n_extra= [0,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class ModelSetup:\n",
    "    \n",
    "    def __init__( self, pos_net, neg_net, w, b, batch_size, num_unrollings, drop_prob_list, name=''):\n",
    "    \n",
    "        # 1. Create placeholders for inputs \n",
    "        self.X = list()\n",
    "        for iaux in range(num_unrollings + 1):\n",
    "            self.X.append(tf.placeholder(tf.float32, shape=[batch_size, vc.vocabulary_size], \n",
    "                                             name= name+'X_i'+str(iaux)+'_All'))\n",
    "        aux_inputs = self.X[:num_unrollings]\n",
    "        aux_labels = self.X[1:]  # inputs shifted by one time step.\n",
    "\n",
    "        # Create a list for store the placeholders for the labels\n",
    "        self.labels = tf.placeholder(tf.float32, shape=[batch_size, 1])\n",
    "       \n",
    "\n",
    "        # -------------------- unrolling of the network --------------------------- # \n",
    "        self.pos_unroll, _= pos_net.unrolling_setup( batch_size, num_unrollings, \n",
    "                                                     inputs_list= aux_inputs,\n",
    "                                                     labels_list= aux_labels,\n",
    "                                                     drop_prob_list= drop_prob_list,\n",
    "                                                     reset_between_unrollings= True,\n",
    "                                                   )\n",
    "\n",
    "        self.neg_unroll, _= neg_net.unrolling_setup( batch_size, num_unrollings, \n",
    "                                                     inputs_list= aux_inputs,\n",
    "                                                     labels_list= aux_labels,\n",
    "                                                     drop_prob_list= drop_prob_list,\n",
    "                                                     reset_between_unrollings= True,\n",
    "                                                   ) \n",
    "\n",
    "\n",
    "        # Classifier.\n",
    "        # error_per_sample is a vector, its shape is changed to have each unrolling in separate columns\n",
    "        output_pos= tf.reshape(self.pos_unroll.error_per_sample,[num_unrollings,batch_size])  \n",
    "        output_neg= tf.reshape(self.neg_unroll.error_per_sample,[num_unrollings,batch_size]) \n",
    "\n",
    "        output_pos_mean= tf.reduce_mean(output_pos, reduction_indices= 0) \n",
    "        output_neg_mean= tf.reduce_mean(output_neg, reduction_indices= 0) \n",
    "\n",
    "        output_mean= tf.transpose(tf.pack( [ output_pos_mean, output_neg_mean ]))\n",
    "\n",
    "\n",
    "        self.logits = tf.nn.xw_plus_b( output_mean , w, b )\n",
    "\n",
    "\n",
    "        self.error_per_sample= tf.nn.sigmoid_cross_entropy_with_logits( self.logits, self.labels )\n",
    "        \n",
    "        # prediction error\n",
    "        #Lp = tf.reduce_mean( tf.mul(self.labels, output_pos_mean) + tf.mul(self.labels-1, output_neg_mean))\n",
    "        Lp = tf.reduce_mean( tf.mul(tf.squeeze(self.labels), output_pos_mean) + \n",
    "                             tf.mul(tf.squeeze(1-self.labels), output_neg_mean)\n",
    "                           )\n",
    "        # c-p penalty\n",
    "        Lcp = tf.reduce_mean( tf.mul(tf.squeeze(1-self.labels), tf.exp(-output_pos_mean)) + \n",
    "                              tf.mul(tf.squeeze(self.labels), tf.exp(-output_neg_mean))\n",
    "                            )\n",
    "        \n",
    "        #Lcp = tf.reduce_mean( tf.mul(tf.squeeze(1-self.labels), tf.reduce_mean(tf.exp(-output_pos), reduction_indices= 0) ) + \n",
    "        #                      tf.mul(tf.squeeze(self.labels), tf.reduce_mean(tf.exp(-output_neg), reduction_indices= 0) )\n",
    "        #                    )\n",
    "        \n",
    "        # regularization\n",
    "        l2_c= tf.nn.l2_loss(w)\n",
    "        \n",
    "        # loss\n",
    "        #self.loss = tf.reduce_mean( self.error_per_sample ) + alpha*Lp + beta*(1.0/Lcp)\n",
    "        #self.loss = tf.reduce_mean( self.error_per_sample ) + alpha*Lp - beta*(Lcp)\n",
    "        self.alpha_r = tf.placeholder(tf.float32)\n",
    "        self.beta_r = tf.placeholder(tf.float32)\n",
    "        \n",
    "        self.loss = tf.reduce_mean( self.error_per_sample ) + self.alpha_r*Lp + self.beta_r*Lcp + lambda_w*l2_c\n",
    "        \n",
    "        # classification error\n",
    "        self.error = tf.reduce_mean( tf.to_float(tf.not_equal( tf.greater(tf.nn.sigmoid(self.logits), 0.5), \n",
    "                                                               tf.greater(self.labels, 0.5))) )\n",
    "        \n",
    "        # perplexity measure\n",
    "        next_words_prob_pos = -tf.log( tf.nn.softmax( self.pos_unroll.y ) + 1e-10)\n",
    "        next_words_prob_neg = -tf.log( tf.nn.softmax( self.neg_unroll.y ) + 1e-10)\n",
    "            \n",
    "        next_words=  tf.concat(0,aux_labels) \n",
    "        \n",
    "        logprob_pos= tf.reshape( tf.reduce_sum( next_words_prob_pos * next_words, 1), [batch_size, num_unrollings] )\n",
    "        logprob_neg= tf.reshape( tf.reduce_sum( next_words_prob_neg * next_words, 1), [batch_size, num_unrollings] )  \n",
    "               \n",
    "        #self.perplexity_pos( -tf.log( prob_pos + 1e-10 ) * self.labels )\n",
    "        #self.perplexity_neg( -tf.log( prob_neg + 1e-10 ) * (1-self.labels) )\n",
    "        self.perplexity_pos = tf.reduce_sum( logprob_pos * self.labels )/(batch_size/2.0) \n",
    "        self.perplexity_neg = tf.reduce_sum( logprob_neg * (1-self.labels) )/(batch_size/2.0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "graph = tf.Graph()\n",
    "with graph.as_default():\n",
    "    # For dropout\n",
    "    drop_prob = tf.placeholder(tf.float32)\n",
    "    drop_prob_list = [ drop_prob for i in range(len(num_nodes)+1)]\n",
    "    drop_prob_list[0]= None\n",
    "     \n",
    "    # 1. Define positive and negative neural networks\n",
    "    pos_net= myLstmNet( num_inputs, num_nodes, num_outputs, n_extra= n_extra,\n",
    "                        afunction=activation_function, \n",
    "                        LstmCell= AlexLstmCell,\n",
    "                        name= pos_net_name)\n",
    "        \n",
    "    neg_net= myLstmNet( num_inputs, num_nodes, num_outputs, n_extra= n_extra,\n",
    "                        afunction=activation_function, \n",
    "                        LstmCell= AlexLstmCell,\n",
    "                        name= neg_net_name)\n",
    "    \n",
    "    # Classifier weights and biases.\n",
    "    #w = tf.Variable(tf.truncated_normal([2, 1], -0.1, 0.1), name=('w_class')) # unconstrained w\n",
    "    #w = tf.Variable(tf.constant( [[-2.0], [2.0]]), name=('w_class'), trainable=False) # fixed w\n",
    "    \n",
    "    #w = tf.Variable(tf.truncated_normal([1, 1], 0.3, 0.4), name=('w_class')) # unconstrained w\n",
    "    w = tf.Variable(tf.constant( [[0.3]] ), name=('w_class')) # fixed w\n",
    "    w = tf.concat(0, [-w, w])\n",
    "    \n",
    "    b = tf.Variable(tf.zeros([1]), name=('b_class'), trainable=Allow_Bias)\n",
    "    \n",
    "    \n",
    "    \n",
    "    # 2. Define unrolling for training\n",
    "    train= ModelSetup( pos_net, neg_net, w, b, batch_size, num_unrollings, \n",
    "                       drop_prob_list, \n",
    "                       name='train_')\n",
    "       \n",
    "    # 3. Define unrolling for validation\n",
    "    if allow_valid:\n",
    "        valid= ModelSetup( pos_net, neg_net, w, b, batch_size_val, num_unrollings_val, \n",
    "                           drop_prob_list= [None for dummy in range(len(num_nodes))], \n",
    "                           name='valid_')\n",
    "        \n",
    "    # 4. Define unrolling for testing\n",
    "    if allow_test:\n",
    "        test= ModelSetup( pos_net, neg_net, w, b, batch_size_test, num_unrollings_test, \n",
    "                          drop_prob_list= [None for dummy in range(len(num_nodes))], \n",
    "                          name='test_')\n",
    "    \n",
    "    # 5. Define unrolling for testing generator\n",
    "    pos_gen_test, _= pos_net.unrolling_setup( 1, 1, drop_prob_list= [None, None, None, None, None] )\n",
    "    neg_gen_test, _= neg_net.unrolling_setup( 1, 1, drop_prob_list= [None, None, None, None, None] )\n",
    "    \n",
    "          \n",
    "    \n",
    "    # 6. Define optimizer    \n",
    "    # 1. specify the optimizer\n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate) # ADAM 0.001\n",
    "    \n",
    "    # 2. get the gradients and variables\n",
    "    # grads_and_vars is a list of tuples (gradient, variable). \n",
    "    grads_and_vars = optimizer.compute_gradients(train.loss) \n",
    "    gradients, v = zip(*grads_and_vars)\n",
    "    \n",
    "    # 3. process the gradients\n",
    "    gradients, _ = tf.clip_by_global_norm(gradients, grad_clip_thresh)  #1.25 #0.025 #0.001(last used)\n",
    "    # 4. apply the gradients to the optimization procedure\n",
    "    optimizer = optimizer.apply_gradients( zip(gradients, v) ) # ADAM\n",
    "    \n",
    "    # for prediction\n",
    "    train_pred = tf.nn.sigmoid(train.logits)\n",
    "    \n",
    "    # Saver\n",
    "    saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Train Energy predictor model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if not os.path.exists(os.path.join(working_dir,\"weights\")):\n",
    "    os.makedirs(os.path.join(working_dir,\"weights\"))\n",
    "\n",
    "reload_pos= False\n",
    "load_pos_file=  working_dir+\"/weights/Weights_LSTM_\" + model_version +\"_\"+ str(num_nodes[0]) + \"u_\"+ \\\n",
    "                \"1r_pos.ckpt\"\n",
    "    \n",
    "reload_neg= False\n",
    "load_neg_file= working_dir+\"/weights/Weights_LSTM_\" + model_version +\"_\"+ str(num_nodes[0]) + \"u_\"+ \\\n",
    "                \"1r_neg.ckpt\"\n",
    "\n",
    "reload_all= True\n",
    "load_all_file=  working_dir+\"/weights/Weights_LSTM_\" + model_version +\"_\"+ str(num_nodes[0]) + \"u_\"+ \\\n",
    "                str(current_run-1) +\"r_All\"+comment+\".ckpt\";\n",
    "\n",
    "save_all= True\n",
    "save_all_file=  working_dir+\"/weights/Weights_LSTM_\" + model_version +\"_\"+ str(num_nodes[0]) + \"u_\"+ \\\n",
    "                str(current_run) +\"r_All\"+comment+\".ckpt\";"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if current_run==1:\n",
    "    reload_all= False;\n",
    "else:\n",
    "    reload_pos= False;\n",
    "    reload_neg= False;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-13-dd312af69b61>:27 in <module>.: initialize_all_variables (from tensorflow.python.ops.variables) is deprecated and will be removed after 2017-03-02.\n",
      "Instructions for updating:\n",
      "Use `tf.global_variables_initializer` instead.\n",
      "Weights Initialized\n",
      "step | Train_err | Valid_err | loss\n",
      "0 | 0.500000 | 0.473750 | 83.598579 | 25.984723\n",
      "50 | 0.345938 | 0.309375 | 68.017072 | 74.854551\n",
      "100 | 0.290000 | 0.280625 | 62.574645 | 124.058069\n",
      "150 | 0.275938 | 0.239375 | 60.364482 | 172.746984\n",
      "200 | 0.260000 | 0.247500 | 57.679037 | 221.541719\n",
      "250 | 0.218750 | 0.225625 | 55.972792 | saved\n",
      "300 | 0.246250 | 0.229687 | 55.045045 | 375.623380\n",
      "350 | 0.232187 | 0.232187 | 54.555505 | 424.370842\n",
      "400 | 0.215938 | 0.210313 | 53.959227 | saved\n",
      "450 | 0.225312 | 0.227813 | 53.559940 | 577.800272\n",
      "500 | 0.213438 | 0.214688 | 53.126650 | 625.041436\n",
      "550 | 0.213125 | 0.204063 | 52.925600 | saved\n",
      "600 | 0.218125 | 0.223750 | 52.728244 | 778.173798\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "\n",
      "650 | 0.217188 | 0.202500 | 52.490865 | saved\n",
      "700 | 0.207187 | 0.199687 | 52.262817 | saved\n",
      "750 | 0.193125 | 0.214688 | 51.927787 | 1031.258729\n",
      "800 | 0.193438 | 0.185938 | 51.573746 | saved\n",
      "850 | 0.196250 | 0.207187 | 51.679579 | 1180.236010\n",
      "900 | 0.183438 | 0.200937 | 51.486271 | 1226.879703\n",
      "950 | 0.195625 | 0.178125 | 51.448093 | saved\n",
      "1000 | 0.192188 | 0.206250 | 51.130481 | 1378.212077\n",
      "1050 | 0.195000 | 0.197813 | 51.250559 | 1424.888449\n",
      "1100 | 0.195000 | 0.186562 | 51.162209 | 1471.579787\n",
      "1150 | 0.191875 | 0.208437 | 51.004813 | 1518.250768\n",
      "1200 | 0.192188 | 0.178437 | 50.607700 | 1564.994681\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "\n",
      "1250 | 0.173437 | 0.210313 | 50.444237 | 1611.663359\n",
      "1300 | 0.177500 | 0.197187 | 50.677055 | 1658.415810\n",
      "1350 | 0.161562 | 0.175937 | 50.342980 | saved\n",
      "1400 | 0.138750 | 0.194062 | 50.286332 | 1817.062813\n",
      "1450 | 0.129062 | 0.183438 | 49.835511 | 1863.841808\n",
      "1500 | 0.139375 | 0.181562 | 49.827760 | 1910.428938\n",
      "1550 | 0.129375 | 0.194375 | 49.758515 | 1957.101604\n",
      "1600 | 0.109687 | 0.172187 | 49.612208 | saved\n",
      "1650 | 0.123438 | 0.192812 | 49.459483 | 2103.744285\n",
      "1700 | 0.101562 | 0.193438 | 49.199207 | 2151.277640\n",
      "1750 | 0.106875 | 0.178750 | 49.177526 | 2199.185529\n",
      "1800 | 0.101250 | 0.208125 | 49.219637 | 2245.525985\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "\n",
      "1850 | 0.102813 | 0.188750 | 49.122311 | 2291.800081\n",
      "1900 | 0.085938 | 0.175000 | 49.144377 | 2337.864559\n",
      "1950 | 0.086875 | 0.190938 | 48.933257 | 2383.998757\n",
      "2000 | 0.081250 | 0.184062 | 48.621822 | 2429.989456\n",
      "2050 | 0.072500 | 0.181250 | 48.762741 | 2475.872056\n",
      "2100 | 0.066250 | 0.198125 | 48.638516 | 2521.961059\n",
      "2150 | 0.070000 | 0.165937 | 48.670040 | saved\n",
      "2200 | 0.065937 | 0.188125 | 48.452095 | 2674.291463\n",
      "2250 | 0.070938 | 0.192812 | 48.604408 | 2720.402739\n",
      "2300 | 0.065937 | 0.178437 | 48.569195 | 2766.412688\n",
      "2350 | 0.065000 | 0.201563 | 48.534321 | 2812.352581\n",
      "2400 | 0.060000 | 0.188438 | 48.109475 | 2858.386067\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "\n",
      "2450 | 0.055000 | 0.193750 | 48.191499 | 2904.321271\n",
      "2500 | 0.055625 | 0.204375 | 48.269434 | 2950.294414\n",
      "2550 | 0.041563 | 0.180312 | 48.226854 | 2996.252532\n",
      "2600 | 0.037500 | 0.193750 | 48.154166 | 3042.249005\n",
      "2650 | 0.038750 | 0.193750 | 47.784786 | 3088.088459\n",
      "2700 | 0.036562 | 0.175937 | 47.839660 | 3133.965827\n",
      "2750 | 0.038437 | 0.194688 | 47.799533 | 3179.855466\n",
      "2800 | 0.027187 | 0.181250 | 47.689375 | 3225.649391\n",
      "2850 | 0.032188 | 0.190938 | 47.528691 | 3271.603873\n",
      "2900 | 0.026875 | 0.198125 | 47.435073 | 3317.543192\n",
      "2950 | 0.021250 | 0.178125 | 47.328120 | 3363.641386\n",
      "3000 | 0.027500 | 0.197187 | 47.473400 | 3409.648063\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "\n",
      "3050 | 0.018437 | 0.192812 | 47.414833 | 3455.673574\n",
      "3100 | 0.020313 | 0.176875 | 47.440417 | 3501.615164\n",
      "3150 | 0.017812 | 0.205000 | 47.290695 | 3547.340127\n",
      "3200 | 0.021562 | 0.194688 | 47.030523 | 3593.359514\n",
      "3250 | 0.011562 | 0.188125 | 47.123620 | 3639.219726\n",
      "3300 | 0.016875 | 0.201250 | 47.027441 | 3684.977111\n",
      "3350 | 0.011250 | 0.170000 | 47.074485 | 3730.815370\n",
      "3400 | 0.010937 | 0.196250 | 46.883313 | 3776.945968\n",
      "3450 | 0.015625 | 0.191875 | 47.099141 | 3823.032298\n",
      "3500 | 0.010000 | 0.185625 | 47.066013 | 3869.077345\n",
      "3550 | 0.012812 | 0.199375 | 47.046849 | 3914.971971\n",
      "3600 | 0.009687 | 0.191250 | 46.639998 | 3960.797932\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "\n",
      "3650 | 0.009687 | 0.181875 | 46.776174 | 4006.625671\n",
      "3700 | 0.008125 | 0.215938 | 46.773168 | 4052.671690\n",
      "3750 | 0.006875 | 0.177500 | 46.865210 | 4098.795878\n",
      "3800 | 0.005625 | 0.205000 | 46.779564 | 4144.790474\n",
      "3850 | 0.005000 | 0.195000 | 46.556528 | 4191.024317\n",
      "3900 | 0.004063 | 0.177813 | 46.497199 | 4237.075818\n",
      "3950 | 0.004375 | 0.204375 | 46.562749 | 4283.029823\n",
      "4000 | 0.004063 | 0.197500 | 46.431810 | 4329.066838\n",
      "4050 | 0.004375 | 0.185625 | 46.300597 | 4375.055287\n",
      "4100 | 0.002812 | 0.207500 | 46.253985 | 4421.027925\n",
      "4150 | 0.000937 | 0.175000 | 46.157899 | 4466.954579\n",
      "4200 | 0.003125 | 0.200937 | 46.273273 | 4512.906371\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "\n",
      "4250 | 0.002188 | 0.198125 | 46.303266 | 4558.932238\n",
      "4300 | 0.003750 | 0.179375 | 46.379248 | 4604.824481\n",
      "4350 | 0.002188 | 0.206875 | 46.173553 | 4650.628566\n",
      "4400 | 0.002500 | 0.188438 | 45.939935 | 4696.597330\n",
      "4450 | 0.001563 | 0.183125 | 46.018132 | 4742.490461\n",
      "4500 | 0.002188 | 0.200313 | 45.973963 | 4788.467771\n",
      "4550 | 0.000937 | 0.172500 | 46.037052 | 4834.406445\n",
      "4600 | 0.001563 | 0.205937 | 45.843614 | 4880.426434\n",
      "4650 | 0.002500 | 0.193750 | 46.060852 | 4926.214875\n",
      "4700 | 0.001250 | 0.185625 | 46.048745 | 4972.047525\n",
      "4750 | 0.003125 | 0.202813 | 46.021687 | 5017.911785\n",
      "4800 | 0.000937 | 0.189375 | 45.720669 | 5063.881159\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "\n",
      "4850 | 0.002188 | 0.190000 | 45.763190 | 5109.618482\n",
      "4900 | 0.002500 | 0.208437 | 45.872754 | 5155.445768\n",
      "4950 | 0.000625 | 0.193438 | 45.910542 | 5201.416040\n",
      "5000 | 0.000313 | 0.206250 | 45.941854 | 5247.442535\n",
      "5050 | 0.000313 | 0.204375 | 45.682013 | 5293.291846\n",
      "5100 | 0.000313 | 0.183438 | 45.640249 | 5339.072043\n",
      "5150 | 0.002188 | 0.198125 | 45.705698 | 5385.024886\n",
      "5200 | 0.000937 | 0.200313 | 45.605544 | 5431.142831\n",
      "5250 | 0.002188 | 0.187812 | 45.470226 | 5477.010851\n",
      "5300 | 0.000625 | 0.206875 | 45.406141 | 5523.010665\n",
      "5350 | 0.000313 | 0.185625 | 45.377560 | 5568.958023\n",
      "5400 | 0.000313 | 0.202187 | 45.481940 | 5614.860166\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "\n",
      "5450 | 0.000625 | 0.198125 | 45.514442 | 5660.776179\n",
      "5500 | 0.001563 | 0.181562 | 45.547968 | 5706.857783\n",
      "5550 | 0.000313 | 0.198125 | 45.404833 | 5752.658829\n",
      "5600 | 0.000313 | 0.193125 | 45.189350 | 5798.679327\n",
      "5650 | 0.001250 | 0.191250 | 45.214789 | 5844.673628\n",
      "5700 | 0.000625 | 0.205937 | 45.336760 | 5890.539899\n",
      "5750 | 0.000937 | 0.188750 | 45.181664 | 5936.382403\n",
      "5800 | 0.000000 | 0.198437 | 45.253230 | 5982.366209\n",
      "5850 | 0.000625 | 0.205313 | 45.249421 | 6028.333009\n",
      "5900 | 0.000313 | 0.182188 | 45.400965 | 6074.420312\n",
      "5950 | 0.001563 | 0.203125 | 45.212855 | 6120.182340\n",
      "Learning finished, weights saved in file: /home/marinodl/research/deep_learning/co_generation_classification/sentiment_analysis_imdb/weights/Weights_LSTM_L2_100u_1r_All_noDropout_LcLpLcp_64unrol_standarloss.ckpt\n"
     ]
    }
   ],
   "source": [
    "num_steps = 6000 \n",
    "summary_frequency = 50\n",
    "n_valid_tests = 50\n",
    "n_characters_step= num_unrollings*batch_size\n",
    "\n",
    "train_error_l= list()\n",
    "valid_error_l= list()\n",
    "\n",
    "if allow_gpu:\n",
    "    config= None\n",
    "else:\n",
    "    config = tf.ConfigProto( device_count = {'GPU': 0} )\n",
    "\n",
    "aux_print=0\n",
    "with tf.Session(graph=graph, config=config) as session:\n",
    "    # -------------------------------- Load weigths from file, or initialize variables ------------------------------------\n",
    "    if reload_all:\n",
    "        saver.restore(session, load_all_file)\n",
    "        #session.run( global_step.assign(0) ) # SGD\n",
    "        \n",
    "    elif (reload_pos and reload_neg):\n",
    "        tf.initialize_all_variables().run()\n",
    "        pos_net.saver.restore(session, load_pos_file)\n",
    "        neg_net.saver.restore(session, load_neg_file)\n",
    "        print('Weights for positive and negative networks loaded')\n",
    "    else:\n",
    "        tf.initialize_all_variables().run()\n",
    "        print('Weights Initialized')\n",
    "    \n",
    "    # ------------------------------------------- Training loop --------------------------------------------------\n",
    "    print('step | Train_err | Valid_err | loss')\n",
    "    \n",
    "    mean_loss = 0.0\n",
    "    mean_error = 0.0\n",
    "    \n",
    "    start_time = time.time()\n",
    "    \n",
    "    for step in range(num_steps):\n",
    "        # 1. Get next batch\n",
    "        batch_X, batch_y = dataset.train.next_batch()\n",
    "        \n",
    "        # 2. Setup feed dictionary for network 1 and network 2\n",
    "        feed_dict = dict()\n",
    "        # For dropout\n",
    "        feed_dict[drop_prob] = dropout_cons\n",
    "        # hyperparameters\n",
    "        feed_dict[train.alpha_r] = alpha\n",
    "        feed_dict[train.beta_r] = beta\n",
    "            \n",
    "        # Inroduce labels\n",
    "        feed_dict[train.labels] = batch_y\n",
    "        # Introduce inputs\n",
    "        for i in range(num_unrollings+1):\n",
    "            feed_dict[train.X[i]] = batch_X[i]\n",
    "              \n",
    "        # 3 Run optimizer\n",
    "        #_, l, lr = session.run( [optimizer, loss_train, learning_rate], feed_dict=feed_dict) # SGD\n",
    "        _, l, train_error = session.run( [optimizer, train.loss, train.error], feed_dict=feed_dict) # ADAM\n",
    "        \n",
    "        mean_loss += l\n",
    "        mean_error += train_error #classification_error(pred_train_aux, batch_y) \n",
    "        \n",
    "        # --------------------------------------------- logging ------------------------------------------------\n",
    "        if dataset.train.batch_generators[0]._text_size<aux_print :\n",
    "            print('+'*80)\n",
    "            print('')\n",
    "            aux_print = 0\n",
    "        else:\n",
    "            aux_print += n_characters_step\n",
    "        \n",
    "        if step % summary_frequency == 0:\n",
    "            if step > 0:\n",
    "                mean_loss = mean_loss / summary_frequency\n",
    "                mean_error = mean_error / summary_frequency\n",
    "                        \n",
    "            # ---------- Print loss in validation dataset ---------\n",
    "            if allow_valid:\n",
    "                ''' classification error on validation dataset '''\n",
    "                mean_error_val = 0.0\n",
    "                for step_valid in range(n_valid_tests):\n",
    "                    # 1. Get next batch\n",
    "                    batch_X_val, batch_y_val = dataset.valid.next_batch()        \n",
    "                    feed_dict_val = dict()\n",
    "                    # For dropout\n",
    "                    feed_dict_val[drop_prob] = 1.0\n",
    "                    # Inroduce labels\n",
    "                    feed_dict_val[valid.labels] = batch_y_val\n",
    "                    # Introduce inputs\n",
    "                    for i in range(num_unrollings_val+1):\n",
    "                        feed_dict_val[valid.X[i]] = batch_X_val[i]\n",
    "                    # 2. Get classification error\n",
    "                    [valid_error] = session.run( [valid.error], feed_dict=feed_dict_val)          \n",
    "                    mean_error_val += valid_error\n",
    "                    \n",
    "                mean_error_val = mean_error_val/n_valid_tests\n",
    "                \n",
    "                ''' print information '''\n",
    "                train_error_l.append(mean_error)\n",
    "                valid_error_l.append(mean_error_val)\n",
    "                \n",
    "                if save_all and valid_error_l[-1] == min(valid_error_l) and step>200:\n",
    "                    save_path = saver.save(session, save_all_file)\n",
    "                    print('%d | %f | %f | %f | saved' % (step, \n",
    "                                                         mean_error, \n",
    "                                                         mean_error_val, \n",
    "                                                         mean_loss\n",
    "                                                        ))    \n",
    "                \n",
    "                else:\n",
    "                    cur_time = time.time() - start_time\n",
    "                    print('%d | %f | %f | %f | %f' % (step, \n",
    "                                                      mean_error, \n",
    "                                                      mean_error_val, \n",
    "                                                      mean_loss,\n",
    "                                                      cur_time\n",
    "                                                 ))   \n",
    "                    \n",
    "                #if(mean_error_val < 0.19):\n",
    "                #    break\n",
    "            else:\n",
    "                train_error_l.append(mean_error)\n",
    "                print('%d | %f | %f' % (step, mean_error, mean_loss))\n",
    "                                       \n",
    "            mean_loss = 0\n",
    "            mean_error = 0\n",
    "            \n",
    "    if save_all and allow_valid:\n",
    "        print(\"Learning finished, weights saved in file: %s\" % save_path)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f6c2c9cccc0>]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAg0AAAFkCAYAAACjCwibAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nWHVzcwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f6c2ca80f28>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "train_error_a = np.array(train_error_l)\n",
    "valid_error_a = np.array(valid_error_l)\n",
    "\n",
    "plt.plot(np.linspace(0, train_error_a.shape[0], train_error_a.shape[0]) , train_error_a )\n",
    "plt.plot(np.linspace(0, valid_error_a.shape[0], train_error_a.shape[0]) , valid_error_a )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### classification error on test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-16-81daa8a5883b>:5 in <module>.: initialize_all_variables (from tensorflow.python.ops.variables) is deprecated and will be removed after 2017-03-02.\n",
      "Instructions for updating:\n",
      "Use `tf.global_variables_initializer` instead.\n",
      "Weights loaded\n",
      "Classification error on test dataset: 0.213854166667\n"
     ]
    }
   ],
   "source": [
    "n_tests = 600\n",
    "if allow_test:\n",
    "    with tf.Session(graph=graph) as session:\n",
    "        # Load weigths from file, or initialize variables\n",
    "        tf.initialize_all_variables().run()\n",
    "        saver.restore(session, save_all_file)\n",
    "        print('Weights loaded')\n",
    "        \n",
    "        # calculate errors using mini-batches\n",
    "        mean_error_test = 0\n",
    "        mean_perp_pos = 0\n",
    "        mean_perp_neg = 0\n",
    "        for step_test in range(n_tests):\n",
    "            # 1. Get next batch\n",
    "            batch_X_test, batch_y_test = dataset.test.next_batch()        \n",
    "            feed_dict_test = dict()\n",
    "            # For dropout\n",
    "            feed_dict_test[drop_prob] = 1.0\n",
    "            # Inroduce labels\n",
    "            feed_dict_test[test.labels] = batch_y_test\n",
    "            # Introduce inputs\n",
    "            for i in range(num_unrollings_test+1):\n",
    "                feed_dict_test[test.X[i]] = batch_X_test[i]\n",
    "            # 2. Get prediction\n",
    "            [test_error, perp_pos, perp_neg] = session.run( [test.error, test.perplexity_pos, test.perplexity_neg], \n",
    "                                                            feed_dict=feed_dict_test)          \n",
    "            mean_error_test += test_error\n",
    "            mean_perp_pos += perp_pos\n",
    "            mean_perp_neg += perp_neg\n",
    "            \n",
    "        print(\"Classification error on test dataset:\", mean_error_test/n_tests)\n",
    "        #print(\"Perplexity on positive dataset:\", mean_perp_pos) #TODO\n",
    "        #print(\"Perplexity on negative dataset:\", mean_perp_neg) #TODO\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate some samples from positive and negative networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-17-e126e9462b65>:3 in <module>.: initialize_all_variables (from tensorflow.python.ops.variables) is deprecated and will be removed after 2017-03-02.\n",
      "Instructions for updating:\n",
      "Use `tf.global_variables_initializer` instead.\n",
      "Weights loaded\n",
      "b= [ 0.]\n",
      "w= [[-8.66429901]\n",
      " [ 8.66429901]]\n",
      "a------------------------------pos------------------------------\n",
      "health on the adventur they pass someon man into social other i have to tell he s up here in itali but at all time say that much fantasi final ha \n",
      "hbo are also visual logic in endless manner that film wa veri good the script is made me believ that he got to be the sheriff william h maci work and \n",
      "earn big mark of a period piec by and quit entertain whoever scene presum not the case for exampl she maria is also a heartbreak real life star i m not \n",
      "carl is an eye hous on news than the oppos side of the who put the abov off in mani way to war and there are fine film necessari that scene \n",
      "what is to on her add oscar anyth like fulli miscast as ann might richardson on for those and she disappoint although the is a good show right down to leav \n",
      "a--------------------------------------------------------------------------------\n",
      "a------------------------------neg------------------------------\n",
      "nerd the curs it s bore the whole premis is stupid too slow at open it also isn t that realiz a lot of interest and entertain from the first five \n",
      "lemmon are never interest and engag in the charact with a situat in spooki superhero half hour long stare at best are not onli is the film s littl bit of \n",
      "eyr run one of the most weird kind of in the day of daughter on to the bottom line of return with bad that i suggest thi guy would say at \n",
      "mst k l grand the courag to see him unreal that event total practic dub into arm and puppet in common third one with the product they have five forc to \n",
      "crash into fanci film to go back or decad characterist other and to demand stop their creepi world code they could lack in the book is about the ultra infect of \n",
      "a--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "with tf.Session(graph=graph) as session:\n",
    "    # Load weigths from file, or initialize variables\n",
    "    tf.initialize_all_variables().run()\n",
    "    saver.restore(session, save_all_file)\n",
    "    print('Weights loaded')\n",
    "        \n",
    "    # print values for b and w\n",
    "    b_t= b.eval()\n",
    "    w_t= w.eval()\n",
    "    #b_t= session.run(b)\n",
    "    print('b=', b_t)\n",
    "    print('w=', w_t)\n",
    "    \n",
    "    \n",
    "    # For positive network\n",
    "    print('a' + '-'*30 + 'pos' + '-'*30)\n",
    "    for _ in range(5):\n",
    "        feed = sample(random_distribution())\n",
    "        sentence = vc.prob2char(feed)\n",
    "        pos_gen_test.reset_saved_out_state.run()\n",
    "        for _ in range(30):\n",
    "            prediction = tf.nn.softmax(pos_gen_test.y).eval({pos_gen_test.inputs_list[0]: feed}) # feed is a 1-hot encoding\n",
    "            feed = sample(prediction)  # sample returns a 1-hot encoding\n",
    "            sentence += vc.prob2char(feed)\n",
    "        print(sentence)\n",
    "    print('a' + '-' * 80)\n",
    "    \n",
    "    # For negative network\n",
    "    print('a' + '-'*30 + 'neg' + '-'*30)\n",
    "    for _ in range(5):\n",
    "        feed = sample(random_distribution())\n",
    "        sentence = vc.prob2char(feed)\n",
    "        neg_gen_test.reset_saved_out_state.run()\n",
    "        for _ in range(30):\n",
    "            prediction = tf.nn.softmax(neg_gen_test.y).eval({neg_gen_test.inputs_list[0]: feed}) # feed is a 1-hot encoding\n",
    "            feed = sample(prediction)  # sample returns a 1-hot encoding\n",
    "            sentence += vc.prob2char(feed)\n",
    "        print(sentence)\n",
    "    print('a' + '-' * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
